{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rashmikb26/BoomBike/blob/main/notebook_cement_sales_and_demand_forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VvqqB7dFVpXL"
      },
      "outputs": [],
      "source": [
        "# Cement Sales & Demand Prediction 89"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oxDOeVibVpXO"
      },
      "outputs": [],
      "source": [
        "#importing important Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "SsqV8QP9VpXP",
        "outputId": "38efc61b-6ea0-4111-d975-6713aa8f3278"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-d60ed4adf426>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\" https://raw.githubusercontent.com/rashmikb26/CementSalesForecasting/main/89cement%20data%20.csv?token=GHSAT0AAAAAACSFEYOLCA23IP4Z3BC4BJ7WZSCJKTQ\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# Dataset is now stored in a Pandas Dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ],
      "source": [
        "#loading the data and creating column 't'\n",
        "import os\n",
        "\n",
        "#1) From Github (Files < 25MB)\n",
        "\n",
        "#filename = \"https://github.com/rashmikb26/CementSalesForecasting/blob/main/89cement%20data%20.csv\"\n",
        "# provide the raw data url\n",
        "filename =\" https://raw.githubusercontent.com/rashmikb26/CementSalesForecasting/main/89cement%20data%20.csv?token=GHSAT0AAAAAACSFEYOLCA23IP4Z3BC4BJ7WZSCJKTQ\"\n",
        "url = filename\n",
        "df1 = pd.read_csv(url)\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "cement = pd.read_csv(filename)\n",
        "cement = cement.iloc[:155, :8]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCZFRzRVVpXQ"
      },
      "outputs": [],
      "source": [
        "cement['t'] =np.arange(1,156)\n",
        "cement.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f6GCHgfVpXQ"
      },
      "outputs": [],
      "source": [
        "# Interchanging position of feature t\n",
        "cement = cement.iloc[:, [0,8,1,2,3,4,5,6,7]]\n",
        "cement.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLpEEiqfVpXQ"
      },
      "source": [
        "# AutoEDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rd0xDXCVpXS"
      },
      "outputs": [],
      "source": [
        "# performing autoEDA\n",
        "!pip install pandas-profiling\n",
        "!pip install pydantic-settings\n",
        "\n",
        "from pydantic_settings import BaseSettings\n",
        "import pandas-profiling\n",
        "\n",
        "autoeda = ProfileReport(cement, explorative= True)\n",
        "autoeda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er3QD9ahVpXT"
      },
      "source": [
        "# Correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbCukqWoVpXV"
      },
      "outputs": [],
      "source": [
        "# checking correlation between each features\n",
        "\n",
        "cement.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpFxvwqMVpXW"
      },
      "source": [
        "# Pairplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iaW0DjxVpXW"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(cement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVwi8ZRnVpXX"
      },
      "outputs": [],
      "source": [
        "cement.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjk1qkEyVpXX"
      },
      "source": [
        "# Time Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WrEROxlVpXX"
      },
      "outputs": [],
      "source": [
        "# time plot is basically a line plot showing the evolution of the time series over time.\n",
        "\n",
        "sns.lineplot('t', 'Sales ',data= cement)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gCZU8xoVpXY"
      },
      "outputs": [],
      "source": [
        "sns.lineplot('t', 'Production',data= cement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKs1xYSvVpXY"
      },
      "outputs": [],
      "source": [
        "sns.lineplot('t', 'demand',data= cement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4eakNc4VpXY"
      },
      "outputs": [],
      "source": [
        "sns.lineplot('t', 'population',data= cement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEeTZV4sVpXY"
      },
      "outputs": [],
      "source": [
        "sns.lineplot('t', 'gdp',data= cement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy7rB0UeVpXY"
      },
      "outputs": [],
      "source": [
        "sns.lineplot('t', 'disbusment',data= cement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh_4d6ZhVpXY"
      },
      "outputs": [],
      "source": [
        "sns.lineplot('t', 'interestrate', data= cement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qp7hDkIuVpXZ"
      },
      "outputs": [],
      "source": [
        "cement.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKpHgOqMVpXZ"
      },
      "outputs": [],
      "source": [
        "# checking outliers\n",
        "\n",
        "sns.boxplot(cement['Sales '])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYdSea-QVpXZ"
      },
      "outputs": [],
      "source": [
        "#!pip install feature_engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s952DpStVpXZ"
      },
      "outputs": [],
      "source": [
        "#outliers are present in this feature so need to treat them\n",
        "#lets use Winsorization\n",
        "\n",
        "from feature_engine.outliers import Winsorizer\n",
        "winsor = Winsorizer(capping_method='iqr',\n",
        "                   fold= 1.5,\n",
        "                   tail= 'both',\n",
        "                   variables=['Sales '])\n",
        "cement['Sales '] = winsor.fit_transform(cement[['Sales ']])\n",
        "sns.boxplot(cement['Sales '])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nHJ2CBhVpXZ"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(cement['demand'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LedByWNZVpXZ"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(cement['Production'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTLjcBH-VpXZ"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(cement['population'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_2-VrEFVpXd"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(cement['gdp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPWixVlFVpXd"
      },
      "outputs": [],
      "source": [
        "from feature_engine.outliers import Winsorizer\n",
        "winsor = Winsorizer(capping_method='iqr',\n",
        "                   fold= 1.5,\n",
        "                   tail= 'both',\n",
        "                   variables=['gdp'])\n",
        "cement['gdp'] = winsor.fit_transform(cement[['gdp']])\n",
        "sns.boxplot(cement['gdp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4tqDfBzVpXd"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(cement['disbusment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-Jr43iHVpXd"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(cement['interestrate'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g42BrMmCVpXd"
      },
      "outputs": [],
      "source": [
        "sns.lineplot('t','gdp', data=cement)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Ivcfy4VpXe"
      },
      "source": [
        "# Forecasting for Sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyZbSoXQVpXe"
      },
      "source": [
        "# Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMoqiCeGVpXe"
      },
      "outputs": [],
      "source": [
        "# breaking up a time series into components, most notably: a trend component, a seasonal component, and a residual component\n",
        "\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "decompose_ts_add = seasonal_decompose(cement['Sales '], model = \"additive\", period = 4)\n",
        "print(decompose_ts_add.trend)\n",
        "print(decompose_ts_add.seasonal)\n",
        "print(decompose_ts_add.resid)\n",
        "print(decompose_ts_add.observed)\n",
        "decompose_ts_add.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osh5MKksVpXe"
      },
      "outputs": [],
      "source": [
        "decompose_ts_mul = seasonal_decompose(cement['Sales '], model = \"multiplicative\", period = 4)\n",
        "decompose_ts_mul.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rL_-b0ILVpXe"
      },
      "outputs": [],
      "source": [
        "# filtering requied features for sales forecasting\n",
        "\n",
        "cementsales = cement.loc[:, ['Month','Sales ', 't']]\n",
        "cementsales.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8KrUXhMVpXf"
      },
      "outputs": [],
      "source": [
        "# squaring t value as it will further requied for model\n",
        "\n",
        "cementsales['tsquare'] = cementsales['t'] * cementsales['t']\n",
        "cementsales.head()\n",
        "cementsales.rename(columns = {'Sales ' : 'sales'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etkjLAeQVpXf"
      },
      "outputs": [],
      "source": [
        "# taking the log of sales values as it will be required for the exponential model\n",
        "\n",
        "cementsales['log_cement'] = np.log(cementsales['sales'])\n",
        "\n",
        "cementsales.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBF_lGKEVpXi"
      },
      "outputs": [],
      "source": [
        "p = cementsales[\"Month\"][0]\n",
        "p[0:3]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrEjZPg3VpXi"
      },
      "outputs": [],
      "source": [
        "cementsales['months']= 0\n",
        "\n",
        "for i in range(155):\n",
        "    p = cementsales[\"Month\"][i]\n",
        "    cementsales['months'][i]= p[0:3]\n",
        "\n",
        "cementsales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8_pqSHPVpXj"
      },
      "outputs": [],
      "source": [
        "# converting months catagorical features to numeric columns by using pandas get_dummies function\n",
        "\n",
        "month_dummies = pd.DataFrame(pd.get_dummies(cementsales['months']))\n",
        "month_dummies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqphI1YPVpXj"
      },
      "outputs": [],
      "source": [
        "# concating data\n",
        "\n",
        "cementsales1 = pd.concat([cementsales, month_dummies], axis= 1)\n",
        "cementsales1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y5NuBDTVpXk"
      },
      "outputs": [],
      "source": [
        "cementsales1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Acp3X9TVpXm"
      },
      "outputs": [],
      "source": [
        "# splitting data into train & test\n",
        "\n",
        "train = cementsales1.head(143)\n",
        "test = cementsales1.tail(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nZ_kFWbVpXm"
      },
      "outputs": [],
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLaZkbdPVpXm"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujEP013zVpXm"
      },
      "outputs": [],
      "source": [
        "test.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVtweBIKVpXm"
      },
      "source": [
        "# Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyacZgk2VpXn"
      },
      "outputs": [],
      "source": [
        "#importing linear Model, error matrix for error calculation\n",
        "#checking different models for better accuracy\n",
        "\n",
        "import statsmodels.formula.api as api\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "#Linear Model\n",
        "\n",
        "linear_model = api.ols('sales ~ t', data = train).fit()\n",
        "pred_linear =  pd.Series(linear_model.predict(pd.DataFrame(test['t'])))\n",
        "rmse_linear = np.sqrt(np.mean((np.array(test['sales']) - np.array(pred_linear))**2))\n",
        "mapa_linear = mean_absolute_percentage_error(test['sales'], pd.DataFrame(pred_linear))\n",
        "\n",
        "print('mapa : ', mapa_linear)\n",
        "print('rmse : ',rmse_linear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRNHQ9c5VpXn"
      },
      "outputs": [],
      "source": [
        "# Exponential Model\n",
        "\n",
        "Exp = api.ols('log_cement ~ t', data = train).fit()\n",
        "pred_Exp = pd.Series(Exp.predict(pd.DataFrame(test['t'])))\n",
        "rmse_Exp = np.sqrt(np.mean((np.array(test['sales']) - np.array(np.exp(pred_Exp)))**2))\n",
        "mapa_Exp = mean_absolute_percentage_error(test['sales'], pd.DataFrame(np.exp(pred_Exp)))\n",
        "\n",
        "print('mapa : ', mapa_Exp)\n",
        "print('rmse : ', rmse_Exp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsNXtX2GVpXn"
      },
      "outputs": [],
      "source": [
        "#quadratic model\n",
        "\n",
        "Quad = api.ols('sales ~ t + tsquare', data = train).fit()\n",
        "pred_Quad = pd.Series(Quad.predict(test[[\"t\", \"tsquare\"]]))\n",
        "rmse_Quad = np.sqrt(np.mean((np.array(test['sales']) - np.array(pred_Quad))**2))\n",
        "mapa_Quad = mean_absolute_percentage_error(test['sales'], pd.DataFrame(pred_Quad))\n",
        "\n",
        "print('mapa : ', mapa_Quad)\n",
        "print('rmse : ', rmse_Quad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05dryM__VpXn"
      },
      "outputs": [],
      "source": [
        "# Additive Seasonality\n",
        "\n",
        "add_sea = api.ols('sales ~ Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov', data=train).fit()\n",
        "pred_add_sea = pd.Series(add_sea.predict(test[['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov']]))\n",
        "rmse_add_sea = np.sqrt(np.mean((np.array(test['sales']) - np.array(pred_add_sea))**2))\n",
        "mapa_add_sea = mean_absolute_percentage_error(test['sales'], pd.DataFrame(pred_add_sea))\n",
        "\n",
        "print('mapa : ', mapa_add_sea)\n",
        "print('rmse : ', rmse_add_sea)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNxqH7UUVpXn"
      },
      "outputs": [],
      "source": [
        "# Multiplicative Model\n",
        "\n",
        "Mul_sea = api.ols('log_cement ~ Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov',data = train).fit()\n",
        "pred_Mult_sea = pd.Series(Mul_sea.predict(test))\n",
        "rmse_Mult_sea = np.sqrt(np.mean((np.array(test['sales']) - np.array(np.exp(pred_Mult_sea)))**2))\n",
        "mapa_Mult_sea = mean_absolute_percentage_error(test['sales'], pd.DataFrame(np.exp(pred_Mult_sea)))\n",
        "\n",
        "print('mapa : ', mapa_Mult_sea)\n",
        "print('rmse : ', rmse_Mult_sea)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4T_Ryb_VpXn"
      },
      "outputs": [],
      "source": [
        "# Additive seasionality quadratic trend\n",
        "\n",
        "add_sea_Quad = api.ols('sales ~ t+tsquare+Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov',data=train).fit()\n",
        "pred_add_sea_quad = pd.Series(add_sea_Quad.predict(test[['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','t','tsquare']]))\n",
        "rmse_add_sea_quad = np.sqrt(np.mean((np.array(test['sales'])-np.array(pred_add_sea_quad))**2))\n",
        "mapa_add_sea_quad = mean_absolute_percentage_error(test['sales'], pd.DataFrame(pred_add_sea_quad))\n",
        "\n",
        "print('mapa : ', mapa_add_sea_quad)\n",
        "print('rmse : ', rmse_add_sea_quad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWIZhES0VpXo"
      },
      "outputs": [],
      "source": [
        "# Multiplicative seasonality linear trend\n",
        "\n",
        "Mul_Add_sea = api.ols('log_cement ~ t+Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov',data = train).fit()\n",
        "pred_Mult_add_sea = pd.Series(Mul_Add_sea.predict(test))\n",
        "rmse_Mult_add_sea = np.sqrt(np.mean((np.array(test['sales'])-np.array(np.exp(pred_Mult_add_sea)))**2))\n",
        "mapa_Mult_add_sea = mean_absolute_percentage_error(test['sales'], pd.DataFrame(np.exp(pred_Mult_add_sea)))\n",
        "\n",
        "print('mapa : ', mapa_Mult_add_sea)\n",
        "print('rmse : ', rmse_Mult_add_sea )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9EG1sVQVpXo"
      },
      "outputs": [],
      "source": [
        "# concating data of model, rmse, mapa values so as to select appropriate model for better accuracy\n",
        "\n",
        "data = {\"MODEL\":pd.Series([\"rmse_linear\",\"rmse_Exp\",\"rmse_Quad\",\"rmse_add_sea\",\"rmse_add_sea_quad\",\"rmse_Mult_sea\",\"rmse_Mult_add_sea\"]),\n",
        "        \"RMSE_Values\":pd.Series([rmse_linear,rmse_Exp,rmse_Quad,rmse_add_sea,rmse_add_sea_quad,rmse_Mult_sea,rmse_Mult_add_sea]),\n",
        "       \"MAPA_Values\": pd.Series([mapa_linear,mapa_Exp,mapa_Quad,mapa_add_sea,mapa_add_sea_quad,mapa_Mult_sea,mapa_Mult_add_sea])}\n",
        "table_rmse_mapa = pd.DataFrame(data)\n",
        "table_rmse_mapa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u73wSTuVpXo"
      },
      "source": [
        "from above table we can say that,\n",
        "RMSE_values, MAPA_values for Multiplicative seasonality linear trend model giving us less error,\n",
        "so we can use this model for our prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu52593vVpXo"
      },
      "outputs": [],
      "source": [
        "predict_data = pd.read_csv('/kaggle/input/forecasted-data-89/predictive data project 89.csv')\n",
        "predict_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMUVpOHCVpXp"
      },
      "outputs": [],
      "source": [
        "p1= predict_data[\"month\"][0]\n",
        "p1[0:3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soVTD6ogVpXp"
      },
      "outputs": [],
      "source": [
        "predict_data['months']= 0\n",
        "\n",
        "for i in range(12):\n",
        "    p1 = predict_data[\"month\"][i]\n",
        "    predict_data['months'][i]= p1[0:3]\n",
        "\n",
        "predict_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnEJ_evtVpXp"
      },
      "outputs": [],
      "source": [
        "predict_dummies = pd.DataFrame(pd.get_dummies(predict_data['months']))\n",
        "predict_dummies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMODAc_dVpXp"
      },
      "outputs": [],
      "source": [
        "predict_data = pd.concat([predict_data, predict_dummies], axis= 1)\n",
        "predict_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AicnwhDAVpXp"
      },
      "outputs": [],
      "source": [
        "# Final Model\n",
        "\n",
        "model_full = api.ols('log_cement ~ t+Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov',data = cementsales1).fit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JZUrlymVpXp"
      },
      "outputs": [],
      "source": [
        "pd.Series(model_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEMb5yumVpXp"
      },
      "outputs": [],
      "source": [
        "pred_new = pd.Series(model_full.predict(predict_data))\n",
        "pred_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJVj2gRHVpXq"
      },
      "outputs": [],
      "source": [
        "pred_new_exp = np.exp(pred_new)\n",
        "pred_new_exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdA2UQbxVpXq"
      },
      "outputs": [],
      "source": [
        "# Forecasted values\n",
        "\n",
        "predict_data['prediction_values'] = pred_new_exp\n",
        "predict_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5I70B_GVpXq"
      },
      "source": [
        "# ARIMA model\n",
        "\n",
        "auto_arima() function will be used to automatically select the best parameters for an ARIMA model. It takes several parameters to set a range of values for p, d, q, P, D, Q that the function will explore. For example, start_p=1, start_q=1 and max_p=3, max_q=3 are set as the range for p and q.\n",
        "\n",
        "\n",
        "The auto_arima() model will use the stepwise=True option to fit the model iteratively and improve the model at each step.\n",
        "\n",
        "\n",
        "The fitted model is then stored in the model_fit variable and the summary of the model is printed.\n",
        "\n",
        "\n",
        "Finally, the code uses the predict() function of the fitted model to forecast the next 'n' periods of the time series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnMGXfaRVpXq"
      },
      "outputs": [],
      "source": [
        "#!pip install pmdarima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4QFd9ynVpXq"
      },
      "outputs": [],
      "source": [
        "#importing auto arima so as to get values of (p, d, q) for Arima model\n",
        "\n",
        "from pmdarima import auto_arima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nN1EYB-VpXr"
      },
      "outputs": [],
      "source": [
        "# Run combinations of ARIMA(p,d,q)\n",
        "model_fit = auto_arima(train['sales'],\n",
        "                       m=12,\n",
        "                       d=0,\n",
        "                       D=0,\n",
        "                       max_order=None,\n",
        "                       max_p=7,\n",
        "                       max_q=7,\n",
        "                       max_d=2,\n",
        "                       max_P=4,\n",
        "                       max_Q=4,\n",
        "                       max_D=2,\n",
        "                       maxiter = 50,\n",
        "                       alpha = 0.05,\n",
        "                       n_jobs = -1,\n",
        "                       seasonal=True,\n",
        "                       trace=True,\n",
        "                       error_action='ignore',\n",
        "                       suppress_warnings=True,\n",
        "                       stepwise=True\n",
        "                      )\n",
        "model_fit.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvQaA5NdVpXr"
      },
      "outputs": [],
      "source": [
        "model_fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5Pi659MVpXr"
      },
      "source": [
        "using best model parameter that got from auto-arima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsiIcQRoVpXr"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "# Fit the ARIMA model\n",
        "\n",
        "model_ARIMA = ARIMA(train['sales'],\n",
        "              order=(2,0,0),\n",
        "              seasonal_order=(1, 0, 2, 12))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD_Pe6T3VpXr"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "model_ARIMA = model_ARIMA.fit()\n",
        "\n",
        "train_forecast = train.copy()\n",
        "test_forecast = test.copy()\n",
        "\n",
        "train_forecast['forecast_ARIMA'] = model_ARIMA.predict()\n",
        "train_forecast[['sales','forecast_ARIMA']].plot(figsize=(20,8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNXEIoHBVpXs"
      },
      "outputs": [],
      "source": [
        "#checking RMSE, MAE, MAPA values for train data\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "\n",
        "print(\"RMSE of Auto ARIMA:\", np.sqrt(mean_squared_error(train_forecast['sales'], train_forecast['forecast_ARIMA'])))\n",
        "print(\"MAE of Auto ARIMA:\", mean_absolute_error(train_forecast['sales'], train_forecast['forecast_ARIMA']))\n",
        "print(\"MAPA of Auto ARIMA:\", mean_absolute_percentage_error(train_forecast['sales'], train_forecast['forecast_ARIMA']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSgm5docVpXs"
      },
      "source": [
        "#forcasting on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZojpzDn9VpXs"
      },
      "outputs": [],
      "source": [
        "# Forecast and compare against test data\n",
        "\n",
        "# start date\n",
        "start = len(train)\n",
        "\n",
        "# End date\n",
        "end = len(train)+len(test)-1\n",
        "\n",
        "test_forecast['forecast_ARIMA'] = model_ARIMA.predict(start=start, end=end)\n",
        "test_forecast[['sales','forecast_ARIMA']].plot(figsize=(20,8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja06T_sXVpXs"
      },
      "outputs": [],
      "source": [
        "#checking RMSE, MAE, MAPA values for test data\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "\n",
        "print(\"RMSE of Auto ARIMA:\", np.sqrt(mean_squared_error(test_forecast['sales'], test_forecast['forecast_ARIMA'])))\n",
        "print(\"MAE of Auto ARIMA:\", mean_absolute_error(test_forecast['sales'], test_forecast['forecast_ARIMA']))\n",
        "print(\"MAPE of Auto ARIMA:\", mean_absolute_percentage_error(test_forecast['sales'], test_forecast['forecast_ARIMA']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQr45vpgVpXs"
      },
      "source": [
        "# Forcasting for Demand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVB9i-9lVpXs"
      },
      "source": [
        "# Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NecO6wlVpXt"
      },
      "outputs": [],
      "source": [
        "# breaking up a time series into components, most notably: a trend component, a seasonal component, and a residual component\n",
        "\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "decompose_ts_add1 = seasonal_decompose(cement['demand'], model = \"additive\", period = 12)\n",
        "print(decompose_ts_add1.trend)\n",
        "print(decompose_ts_add1.seasonal)\n",
        "print(decompose_ts_add1.resid)\n",
        "print(decompose_ts_add1.observed)\n",
        "decompose_ts_add1.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ3S3i2gVpXt"
      },
      "outputs": [],
      "source": [
        "decompose_ts_mul1 = seasonal_decompose(cement['demand'], model = \"multiplicative\", period = 12)\n",
        "decompose_ts_mul1.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY4CBbWeVpXt"
      },
      "outputs": [],
      "source": [
        "# filtering requied features for sales forecasting\n",
        "\n",
        "cementdemand = cement.loc[:, ['Month','demand', 't']]\n",
        "cementdemand.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPBVHEh2VpXt"
      },
      "outputs": [],
      "source": [
        "# squaring t value as it will further requied for model\n",
        "\n",
        "cementdemand['tsquare'] = cementdemand['t'] * cementdemand['t']\n",
        "cementdemand.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uu_pjmYgVpXt"
      },
      "outputs": [],
      "source": [
        "# taking the log of sales values as it will be required for the exponential model\n",
        "\n",
        "cementdemand['log_cement'] = np.log(cementdemand['demand'])\n",
        "\n",
        "cementdemand.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MCSifjtVpXt"
      },
      "outputs": [],
      "source": [
        "p3 = cementdemand[\"Month\"][0]\n",
        "p3[0:3]\n",
        "\n",
        "cementdemand['months']= 0\n",
        "\n",
        "for i in range(155):\n",
        "    p3 = cementdemand[\"Month\"][i]\n",
        "    cementdemand['months'][i]= p3[0:3]\n",
        "\n",
        "cementdemand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyEE7iekVpXu"
      },
      "outputs": [],
      "source": [
        "# converting months catagorical features to numeric columns by using pandas get_dummies function\n",
        "\n",
        "month_dummies1 = pd.DataFrame(pd.get_dummies(cementdemand['months']))\n",
        "month_dummies1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zJL6M11VpXu"
      },
      "outputs": [],
      "source": [
        "# concating data\n",
        "\n",
        "cementdemand1 = pd.concat([cementdemand, month_dummies1], axis= 1)\n",
        "cementdemand1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81PN7JfsVpXu"
      },
      "outputs": [],
      "source": [
        "cementdemand1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8mKNQ8CVpXu"
      },
      "outputs": [],
      "source": [
        "# splitting data into train & test\n",
        "\n",
        "train1 = cementdemand1.head(143)\n",
        "test1 = cementdemand1.tail(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aJTFbNaVpXu"
      },
      "outputs": [],
      "source": [
        "print(train1.shape)\n",
        "print(test1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvYvEPl6VpXu"
      },
      "outputs": [],
      "source": [
        "train1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxHS3_fCVpXu"
      },
      "outputs": [],
      "source": [
        "test1.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15lCOhOPVpXv"
      },
      "outputs": [],
      "source": [
        "#importing linear Model, error matrix for error calculation\n",
        "#checking different models for better accuracy\n",
        "\n",
        "import statsmodels.formula.api as api\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "#Linear Model\n",
        "\n",
        "linear_model1 = api.ols('demand ~ t', data = train1).fit()\n",
        "pred_linear1 =  pd.Series(linear_model1.predict(pd.DataFrame(test1['t'])))\n",
        "rmse_linear1 = np.sqrt(np.mean((np.array(test1['demand']) - np.array(pred_linear1))**2))\n",
        "mapa_linear1 = mean_absolute_percentage_error(test1['demand'], pd.DataFrame(pred_linear1))\n",
        "\n",
        "print('mapa : ', mapa_linear1)\n",
        "print('rmse : ',rmse_linear1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocN3OKqjVpXv"
      },
      "outputs": [],
      "source": [
        "# Exponential Model\n",
        "\n",
        "Exp1 = api.ols('log_cement ~ t', data = train1).fit()\n",
        "pred_Exp1 = pd.Series(Exp1.predict(pd.DataFrame(test1['t'])))\n",
        "rmse_Exp1 = np.sqrt(np.mean((np.array(test1['demand']) - np.array(np.exp(pred_Exp1)))**2))\n",
        "mapa_Exp1 = mean_absolute_percentage_error(test1['demand'], pd.DataFrame(np.exp(pred_Exp1)))\n",
        "\n",
        "print('mapa : ', mapa_Exp1)\n",
        "print('rmse : ', rmse_Exp1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8TP7bygVpXv"
      },
      "outputs": [],
      "source": [
        "#quadratic model\n",
        "\n",
        "Quad1 = api.ols('demand ~ t + tsquare', data = train1).fit()\n",
        "pred_Quad1 = pd.Series(Quad1.predict(test1[[\"t\", \"tsquare\"]]))\n",
        "rmse_Quad1 = np.sqrt(np.mean((np.array(test1['demand']) - np.array(pred_Quad1))**2))\n",
        "mapa_Quad1 = mean_absolute_percentage_error(test1['demand'], pd.DataFrame(pred_Quad1))\n",
        "\n",
        "print('mapa : ', mapa_Quad1)\n",
        "print('rmse : ', rmse_Quad1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYcXIUFCVpXv"
      },
      "outputs": [],
      "source": [
        "# Additive Seasonality\n",
        "\n",
        "add_sea1 = api.ols('demand ~ Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov', data=train1).fit()\n",
        "pred_add_sea1 = pd.Series(add_sea1.predict(test1[['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov']]))\n",
        "rmse_add_sea1 = np.sqrt(np.mean((np.array(test1['demand']) - np.array(pred_add_sea1))**2))\n",
        "mapa_add_sea1 = mean_absolute_percentage_error(test1['demand'], pd.DataFrame(pred_add_sea1))\n",
        "\n",
        "print('mapa : ', mapa_add_sea1)\n",
        "print('rmse : ', rmse_add_sea1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE8eQ0k6VpXv"
      },
      "outputs": [],
      "source": [
        "# Multiplicative Model\n",
        "\n",
        "Mul_sea1 = api.ols('log_cement ~ Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov',data = train1).fit()\n",
        "pred_Mult_sea1 = pd.Series(Mul_sea1.predict(test1))\n",
        "rmse_Mult_sea1 = np.sqrt(np.mean((np.array(test1['demand']) - np.array(np.exp(pred_Mult_sea1)))**2))\n",
        "mapa_Mult_sea1 = mean_absolute_percentage_error(test1['demand'], pd.DataFrame(np.exp(pred_Mult_sea1)))\n",
        "\n",
        "print('mapa : ', mapa_Mult_sea1)\n",
        "print('rmse : ', rmse_Mult_sea1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLT4GYYFVpXw"
      },
      "outputs": [],
      "source": [
        "# Additive seasionality quadratic trend\n",
        "\n",
        "add_sea_Quad1 = api.ols('demand ~ t+tsquare+Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov',data=train1).fit()\n",
        "pred_add_sea_quad1 = pd.Series(add_sea_Quad1.predict(test1[['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','t','tsquare']]))\n",
        "rmse_add_sea_quad1 = np.sqrt(np.mean((np.array(test1['demand'])-np.array(pred_add_sea_quad1))**2))\n",
        "mapa_add_sea_quad1 = mean_absolute_percentage_error(test1['demand'], pd.DataFrame(pred_add_sea_quad1))\n",
        "\n",
        "print('mapa : ', mapa_add_sea_quad1)\n",
        "print('rmse : ', rmse_add_sea_quad1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62Sllv4-VpXw"
      },
      "outputs": [],
      "source": [
        "# Multiplicative seasonality linear trend\n",
        "\n",
        "Mul_Add_sea1 = api.ols('log_cement ~ t+Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov',data = train1).fit()\n",
        "pred_Mult_add_sea1 = pd.Series(Mul_Add_sea1.predict(test1))\n",
        "rmse_Mult_add_sea1 = np.sqrt(np.mean((np.array(test1['demand'])-np.array(np.exp(pred_Mult_add_sea1)))**2))\n",
        "mapa_Mult_add_sea1 = mean_absolute_percentage_error(test1['demand'], pd.DataFrame(np.exp(pred_Mult_add_sea1)))\n",
        "\n",
        "print('mapa : ', mapa_Mult_add_sea1)\n",
        "print('rmse : ', rmse_Mult_add_sea1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3KayfYPVpXw"
      },
      "outputs": [],
      "source": [
        "# concating data of model, rmse, mapa values so as to select appropriate model for better accuracy\n",
        "\n",
        "data1 = {\"MODEL\":pd.Series([\"rmse_linear\",\"rmse_Exp\",\"rmse_Quad\",\"rmse_add_sea\",\"rmse_add_sea_quad\",\"rmse_Mult_sea\",\"rmse_Mult_add_sea\"]),\n",
        "        \"RMSE_Values\":pd.Series([rmse_linear,rmse_Exp1,rmse_Quad1,rmse_add_sea1,rmse_add_sea_quad1,rmse_Mult_sea1,rmse_Mult_add_sea1]),\n",
        "       \"MAPA_Values\": pd.Series([mapa_linear1,mapa_Exp,mapa_Quad1,mapa_add_sea1,mapa_add_sea_quad1,mapa_Mult_sea1,mapa_Mult_add_sea1])}\n",
        "table_rmse_mapa1 = pd.DataFrame(data1)\n",
        "table_rmse_mapa1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOPLvyhyVpXw"
      },
      "source": [
        "from above table we can say that, RMSE_values, MAPA_values for Multiplicative seasonality linear trend model giving us less error, so we can use this model for our prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCCUDqNuVpXw"
      },
      "source": [
        "# ARIMA Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKGkBfv-VpXw"
      },
      "outputs": [],
      "source": [
        "#importing auto arima so as to get values of (p, d, q) for Arima model\n",
        "\n",
        "from pmdarima import auto_arima\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB7siFjYVpXx"
      },
      "outputs": [],
      "source": [
        "# Run combinations of ARIMA(p,d,q)\n",
        "model_fit1 = auto_arima(train1['demand'],\n",
        "                       m=12,\n",
        "                       d=0,\n",
        "                       D=0,\n",
        "                       max_order=None,\n",
        "                       max_p=7,\n",
        "                       max_q=7,\n",
        "                       max_d=2,\n",
        "                       max_P=4,\n",
        "                       max_Q=4,\n",
        "                       max_D=2,\n",
        "                       maxiter = 50,\n",
        "                       alpha = 0.05,\n",
        "                       n_jobs = -1,\n",
        "                       seasonal=True,\n",
        "                       trace=True,\n",
        "                       error_action='ignore',\n",
        "                       suppress_warnings=True,\n",
        "                       stepwise=True\n",
        "                      )\n",
        "model_fit1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9RtYdwXVpXx"
      },
      "outputs": [],
      "source": [
        "model_fit1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne3JJQpkVpXx"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "# Fit the ARIMA model\n",
        "\n",
        "model_ARIMA1 = ARIMA(train1['demand'],\n",
        "              order=(2,0,0),\n",
        "              seasonal_order=(1, 0, 1, 12))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5tARAC1VpXx"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "model_ARIMA1 = model_ARIMA1.fit()\n",
        "\n",
        "train_forecast1 = train1.copy()\n",
        "test_forecast1 = test1.copy()\n",
        "\n",
        "train_forecast1['forecast_ARIMA1'] = model_ARIMA1.predict()\n",
        "train_forecast1[['demand','forecast_ARIMA1']].plot(figsize=(20,8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeOziarpVpXx"
      },
      "outputs": [],
      "source": [
        "#checking RMSE, MAE, MAPA values for train data\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "\n",
        "print(\"RMSE of Auto ARIMA:\", np.sqrt(mean_squared_error(train_forecast1['demand'], train_forecast1['forecast_ARIMA1'])))\n",
        "print(\"MAE of Auto ARIMA:\", mean_absolute_error(train_forecast1['demand'], train_forecast1['forecast_ARIMA1']))\n",
        "print(\"MAPA of Auto ARIMA:\", mean_absolute_percentage_error(train_forecast1['demand'], train_forecast1['forecast_ARIMA1']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl9w44jfVpXx"
      },
      "source": [
        "#forcasting on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FecypXijVpXx"
      },
      "outputs": [],
      "source": [
        "# Forecast and compare against test data\n",
        "\n",
        "# start date\n",
        "start1 = len(train1)\n",
        "\n",
        "# End date\n",
        "end1 = len(train1)+len(test1)-1\n",
        "\n",
        "test_forecast1['forecast_ARIMA1'] = model_ARIMA1.predict(start=start1, end=end1)\n",
        "test_forecast1[['demand','forecast_ARIMA1']].plot(figsize=(20,8))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nF8pX4_hVpXy"
      },
      "outputs": [],
      "source": [
        "#checking RMSE, MAE, MAPA values for test data\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "\n",
        "print(\"RMSE of Auto ARIMA:\", np.sqrt(mean_squared_error(test_forecast1['demand'], test_forecast1['forecast_ARIMA1'])))\n",
        "print(\"MAE of Auto ARIMA:\", mean_absolute_error(test_forecast1['demand'], test_forecast1['forecast_ARIMA1']))\n",
        "print(\"MAPE of Auto ARIMA:\", mean_absolute_percentage_error(test_forecast1['demand'], test_forecast1['forecast_ARIMA1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARy4wcv_VpXy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}